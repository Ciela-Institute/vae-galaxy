{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import h5py\n",
    "models_path = \"...\\\\Models architecture\" # Replace the ...\n",
    "sys.path.append(models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Galaxy images data into pytorch dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "        self.hdf = h5py.File(file, 'r')\n",
    "        self.datasets = list(self.hdf.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        size = len(self.hdf[self.datasets[0]])\n",
    "        return size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        num_datasets = len(self.datasets)\n",
    "        if num_datasets == 2:\n",
    "            x = self.hdf[self.datasets[0]][idx]\n",
    "            z = self.hdf[self.datasets[1]][idx]\n",
    "            return x, z\n",
    "        else: \n",
    "            x = self.hdf[self.datasets[0]][idx]\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_survey_data= '...\\\\cosmos_25.2_all_with_zphot.h5' # only 128*128 galaxy images \n",
    "deepfield_data = '...\\\\cosmos.h5'  # 158*158 galaxy images + their redshifts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "# Creating the galaxy dataset; galaxy_dataset[integer] outputs a tuple (image, redshift) for the cosmic survey data and just an image for the deepfield_data\n",
    "galaxy_dataset = dataset(cosmic_survey_data)\n",
    "\n",
    "# Splitting galaxy dataset into a training set and a validation set :\n",
    "data_size = len(galaxy_dataset)\n",
    "train_size = int(0.9*data_size)\n",
    "val_size = data_size - train_size\n",
    "\n",
    "Generator = torch.Generator()\n",
    "Generator.manual_seed(0)\n",
    "train_set, val_set = torch.utils.data.random_split(galaxy_dataset, [train_size, val_size], generator = Generator)\n",
    "\n",
    "# Creating the training and validation loaders:\n",
    "batchsize = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batchsize, shuffle = True)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = batchsize, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the deepfield_data, use Model_128vae\n",
    "# For the cosmic_survey_data, use Model_158vae \n",
    "from Model_158vae import VariationalAutoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little word before training our model on the hyperparameter $\\beta$:\n",
    "- To train the model with a fixed $\\beta$, use `vae.train_time(*args)`;\n",
    "- To train the model with a non-fixed $\\beta$ (ex: $\\beta$ increasing over each epoch), use `vae.traintab(*args)`. The shape of the $\\beta$ tensor must be `torch.Size([num_epochs])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9da4cfe36a41aa878bd568d02573e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Models parameters  :\n",
    "nc, nf, z_dim = 1, 64, 64\n",
    "vae = VariationalAutoencoder(nc, nf, z_dim).to(device)\n",
    "\n",
    "# Training parameters:\n",
    "num_epochs = 1\n",
    "lr = 1e-4\n",
    "Beta = 0.1\n",
    "\n",
    "# Time to train ! \n",
    "vae.eval()\n",
    "vae.train()  \n",
    "train_loss, val_loss, mse, kl = vae.train_time(train_loader, val_loader, epochs=num_epochs, learning_rate=lr, beta=Beta)\n",
    "\n",
    "# The terms in output are arrays with the value of the term at each iteration. See Loss.ipynb file to transform it into Loss per epoch and plot the loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model and the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model weights and the losses \n",
    "hyperparameters = {'batch size': batchsize, 'epochs': num_epochs, 'beta': Beta, 'learning rate': lr, 'z_dim': z_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z64_betaIncreasing_loss.pt\n"
     ]
    }
   ],
   "source": [
    "if type(Beta) == torch.Tensor:\n",
    "    beta_behaviour = input(\"Enter a word to describe beta's behaviour\").replace(\" \",\"\")\n",
    "    loss_file_name = \"z\"+str(z_dim)+\"_beta\"+beta_behaviour+\"_loss.pt\"\n",
    "    weights_file_name = \"z\"+str(z_dim)+\"_beta\"+beta_behaviour+\"_weights.pt\"\n",
    "else: \n",
    "    loss_file_name = \"z\"+str(z_dim)+\"_beta\"+str(Beta)+\"_loss.pt\"\n",
    "    weights_file_name = \"z\"+str(z_dim)+\"_beta\"+str(Beta)+\"_weights.pt\"\n",
    "\n",
    "\n",
    "loss_path_deepfield = \"...\\\\\"+loss_file_name\n",
    "loss_path_cosmic_survey = \"...\\\\\"+loss_file_name\n",
    "\n",
    "#torch.save([train_loss, val_loss, mse, kl, hyperparameters], loss_path_deepfield)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d7fd2a48356971e58618481ace9fdf054dd5c32337f32d6ebacd58cdfb77420"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
